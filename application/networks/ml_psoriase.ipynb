{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d123103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/king/mambaforge/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/king/mambaforge/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1289cb81-7898-4a7b-a090-d621f275c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch possibilida o usa facil de gpu\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "#print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a9ffa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando as imagens (image augmentation)\n",
    "#Normalize = normalifor image_file in os.listdir(dir):ze a tensor image with mean and standard deviation.\n",
    "#Pode transformar em grayscale? (acho que nao kkkkk)\n",
    "## Pre processamento\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    #transforms.RandomRotation(50,fill=1),\n",
    "    #transforms.RandomCrop(size=(224, 224)),\n",
    "    #transforms.RandomResizedCrop((224,224)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),  # Converte para tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2175e77f-0299-4841-bb4e-80da9e0348be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a custom dataset (rotulando, etc...)\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data.loc[idx, 'img_name']\n",
    "        image_path = os.path.join(self.img_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        label = str(self.data.loc[idx, 'labels'])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de9d82-6886-4c85-ad8b-108598d447b0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# data = pd.read_csv('data_labels.csv')\n",
    "image_name = data.loc[10, 'img_name']\n",
    "label = data.loc[10,'labels']\n",
    "print(image_name)\n",
    "print('classe: ',label)\n",
    "Image.open(os.path.join('data/',image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9834138a-01c4-47ab-bed0-ed320617feff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_dataset = datasets.ImageFolder(root='data/train/',transform=transform)\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_dataset = CustomDataset(csv_file='train_set.csv', img_dir='data/', transform=transforms,target_transform=None )\n",
    "test_dataset = CustomDataset(csv_file='test_set.csv',img_dir='data/', transform=transforms)\n",
    "val_dataset = CustomDataset(csv_file='val_set.csv',img_dir='data/', transform=transforms)\n",
    "\n",
    "\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bbf80c4-2818-4986-bd82-77f8f3808178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Shape of X [N, C, H, W]: torch.Size([32, 3, 224, 224])\n",
      "Length of X: 32\n",
      "Length/type of y: 32 <class 'tuple'>\n",
      "Size of dataloader: 20\n"
     ]
    }
   ],
   "source": [
    "def get_data_dimensions(dataloader):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        print(batch)\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(f'Length of X: {len(X)}')\n",
    "        print(f\"Length/type of y: {len(y)} {type(y)}\")\n",
    "        print(f\"Size of dataloader: {len(dataloader)}\")\n",
    "        break\n",
    "\n",
    "get_data_dimensions(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27bd6c2-c9de-41f3-9be6-80cc30cbbc58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "\n",
    "\n",
    "def plot_data(dataloader,img_num):\n",
    "    train_features, train_labels = next(iter(dataloader))\n",
    "    for i in range(img_num):\n",
    "        i = randint(0,len(train_features)-1)\n",
    "        img = train_features[i].squeeze().permute(1, 2, 0)\n",
    "        label = train_labels[i]\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        print(f\"Label: {label}\")\n",
    "\n",
    "plot_data(train_loader,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8987ae63-d93e-4546-bbab-3778af8fc2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# O resize da nossa imagem foi para 224x224 e ela é colorida ( 3 channels)\n",
    "input_size = (3, 128, 128)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.zeros(1, *input_size)\n",
    "    output = model.conv_layers(dummy_input)\n",
    "    flattened_output = output.view(output.size(0), -1)\n",
    "    print(flattened_output.size(1))\n",
    "    print(int(flattened_output.size(1)/2))\n",
    "\n",
    "# tamanho correto do tensor de entrada após as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c613cbc0-3add-4d83-8b01-d7e8195fb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o modelo\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "                    #nn.Conv2d(3, 512, kernel_size=3, padding=0), \n",
    "                    #nn.ReLU(),\n",
    "                    #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(3, 224, kernel_size=3, padding=0), \n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(224, 128, kernel_size=3, padding=0),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(128, 64, kernel_size=3, padding=0),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(64, 32, kernel_size=3, padding=0),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(32, 16, kernel_size=3, padding=0),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        flattened_size = self._get_flattened_size(input_size)\n",
    " \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def _get_flattened_size(self, input_size):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_size)\n",
    "            output = self.conv_layers(dummy_input)\n",
    "            flattened_output = self.flatten(output)\n",
    "            return flattened_output.size(1)\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed69382-af97-4ae0-8a24-48fe79125903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#batch_labels_numeric = [class_to_idx[label] for label in batch_labels]\n",
    "class_to_idx = {\"psoriasis\": 0, \"melanome\": 1}\n",
    "\n",
    "\n",
    "def testing_entries(model,dataloader):\n",
    "    size = len(dataloader)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        batch_labels_numeric = [class_to_idx[label] for label in y]\n",
    "        batch_labels_tensor = torch.tensor(batch_labels_numeric).float()\n",
    "        #print(batch)\n",
    "        print('shape tensor imagem:',X.shape)\n",
    "        print('shape tensor y antes tranformacao:',len(y))\n",
    "        print('shape tensor label:',batch_labels_tensor.shape)\n",
    "        print(batch_labels_tensor)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1d38c6-fff7-4e8f-bdc2-c07e1776c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "lst = len(os.listdir('runs/')) # your directory path\n",
    "\n",
    "writer = SummaryWriter(f'runs/ml-model-test-{lst}')\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, class_to_idx):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        batch_labels_numeric = [class_to_idx[label] for label in y]\n",
    "        y = torch.tensor(batch_labels_numeric, dtype=torch.float32)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = model(X)\n",
    "        pred = pred.squeeze(1)\n",
    "\n",
    "        # Compute loss and backpropagation\n",
    "        loss = loss_fn(pred, y)\n",
    "        writer.add_scalar(\"Loss/train\",loss, batch)\n",
    "        loss.backward()\n",
    "        #Performs a single optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            current = batch * 64\n",
    "            print(f\"Loss: {loss.item():.7f}  [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4720c3c0-292d-4097-a8a2-683591f595a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten()\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=7744, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv_layers.0.weight | Size: torch.Size([128, 3, 3, 3]) | Values : tensor([[[[-0.1838, -0.0020,  0.0526],\n",
      "          [ 0.1057,  0.0064, -0.1456],\n",
      "          [-0.0219, -0.0041, -0.0457]],\n",
      "\n",
      "         [[-0.1642,  0.0407, -0.0548],\n",
      "          [-0.1047, -0.1501, -0.1837],\n",
      "          [-0.1388, -0.0918, -0.0666]],\n",
      "\n",
      "         [[ 0.1802, -0.1299, -0.1310],\n",
      "          [-0.1151, -0.1017,  0.0438],\n",
      "          [ 0.1167,  0.1497, -0.0148]]],\n",
      "\n",
      "\n",
      "        [[[-0.0751,  0.0076,  0.0483],\n",
      "          [-0.0166,  0.0473, -0.1901],\n",
      "          [ 0.0326,  0.0125,  0.0194]],\n",
      "\n",
      "         [[-0.1828,  0.1112, -0.1551],\n",
      "          [-0.0508, -0.0276, -0.1083],\n",
      "          [-0.1716,  0.1875, -0.0093]],\n",
      "\n",
      "         [[-0.0417,  0.0157,  0.0438],\n",
      "          [ 0.1557, -0.0808,  0.1386],\n",
      "          [-0.1376, -0.1854, -0.0934]]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.0.bias | Size: torch.Size([128]) | Values : tensor([-0.0256,  0.0342], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.3.weight | Size: torch.Size([64, 128, 3, 3]) | Values : tensor([[[[-5.1120e-03,  2.1686e-02,  2.9126e-02],\n",
      "          [-1.8891e-02,  1.2488e-02, -9.0746e-03],\n",
      "          [ 2.2678e-02,  1.6480e-03, -2.2460e-03]],\n",
      "\n",
      "         [[ 6.9800e-03,  1.3297e-02, -1.4717e-02],\n",
      "          [ 1.8444e-02,  2.4955e-02, -2.1104e-02],\n",
      "          [-4.2616e-03, -1.0176e-03, -1.1383e-03]],\n",
      "\n",
      "         [[ 2.4671e-02, -2.6261e-02, -1.9546e-02],\n",
      "          [-2.8647e-02, -2.1971e-02, -1.0868e-02],\n",
      "          [ 2.1522e-02, -1.3865e-02,  1.7500e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.6160e-04, -2.3047e-02,  2.4064e-02],\n",
      "          [-2.3200e-02, -1.1069e-02, -2.7297e-02],\n",
      "          [-5.0010e-03,  4.2696e-03, -2.3864e-02]],\n",
      "\n",
      "         [[-7.3727e-03,  2.5569e-06, -1.7649e-02],\n",
      "          [-3.5708e-03,  1.8520e-02, -2.5645e-02],\n",
      "          [-2.5241e-02, -1.2636e-02,  2.8820e-02]],\n",
      "\n",
      "         [[ 1.4674e-02,  2.1031e-02,  1.0369e-02],\n",
      "          [-4.0150e-03,  2.6620e-02,  1.4375e-02],\n",
      "          [ 5.5226e-03, -1.3531e-02, -9.2465e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4767e-02, -1.1166e-02,  2.1762e-02],\n",
      "          [-2.8095e-02, -8.3753e-04,  1.7490e-02],\n",
      "          [-1.6985e-02, -2.3059e-02,  7.0558e-03]],\n",
      "\n",
      "         [[ 7.0905e-03, -2.5411e-02, -1.7836e-02],\n",
      "          [ 2.2199e-02,  6.5241e-03, -1.8309e-02],\n",
      "          [-2.1654e-02, -1.9695e-02,  5.6715e-03]],\n",
      "\n",
      "         [[-1.0426e-02,  2.9344e-02,  2.0225e-02],\n",
      "          [ 5.9386e-03, -9.8101e-03,  2.8529e-02],\n",
      "          [ 1.0566e-03, -1.0726e-02, -1.3320e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2815e-03, -1.8982e-02, -1.4643e-02],\n",
      "          [ 2.0350e-02, -1.2549e-02, -1.1712e-02],\n",
      "          [ 1.5542e-02,  2.8080e-02,  5.9602e-04]],\n",
      "\n",
      "         [[-2.2865e-02,  2.2162e-02,  8.3916e-03],\n",
      "          [ 1.8463e-02,  7.7951e-03,  1.7768e-02],\n",
      "          [-4.5773e-03, -2.1349e-02, -2.5198e-02]],\n",
      "\n",
      "         [[ 4.8291e-03,  2.9204e-02,  2.7122e-02],\n",
      "          [ 2.3419e-02,  7.9867e-03,  1.7635e-02],\n",
      "          [-1.9418e-02,  1.3911e-02,  2.9013e-02]]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0003, -0.0132], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.6.weight | Size: torch.Size([32, 64, 3, 3]) | Values : tensor([[[[ 0.0136, -0.0253,  0.0197],\n",
      "          [-0.0277, -0.0084,  0.0074],\n",
      "          [-0.0179, -0.0061,  0.0140]],\n",
      "\n",
      "         [[ 0.0365, -0.0213,  0.0268],\n",
      "          [ 0.0267,  0.0219,  0.0197],\n",
      "          [-0.0277, -0.0248,  0.0127]],\n",
      "\n",
      "         [[ 0.0284,  0.0374,  0.0314],\n",
      "          [ 0.0163, -0.0393,  0.0367],\n",
      "          [-0.0081,  0.0151,  0.0221]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0304,  0.0105, -0.0094],\n",
      "          [-0.0391, -0.0127, -0.0138],\n",
      "          [ 0.0300, -0.0337,  0.0125]],\n",
      "\n",
      "         [[ 0.0341,  0.0028,  0.0416],\n",
      "          [ 0.0122,  0.0090,  0.0029],\n",
      "          [-0.0220,  0.0286,  0.0289]],\n",
      "\n",
      "         [[-0.0356,  0.0131,  0.0115],\n",
      "          [ 0.0232, -0.0230,  0.0274],\n",
      "          [-0.0107,  0.0350, -0.0040]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0037, -0.0236,  0.0298],\n",
      "          [-0.0310, -0.0194, -0.0058],\n",
      "          [ 0.0337,  0.0211,  0.0201]],\n",
      "\n",
      "         [[ 0.0115, -0.0118, -0.0002],\n",
      "          [-0.0299,  0.0328, -0.0186],\n",
      "          [-0.0310,  0.0174,  0.0227]],\n",
      "\n",
      "         [[ 0.0067, -0.0257,  0.0413],\n",
      "          [ 0.0318, -0.0219,  0.0414],\n",
      "          [-0.0202,  0.0079,  0.0161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0398, -0.0141, -0.0263],\n",
      "          [ 0.0372,  0.0277, -0.0362],\n",
      "          [-0.0068, -0.0128, -0.0184]],\n",
      "\n",
      "         [[ 0.0325,  0.0195,  0.0005],\n",
      "          [-0.0133, -0.0075, -0.0005],\n",
      "          [ 0.0313,  0.0032,  0.0036]],\n",
      "\n",
      "         [[ 0.0227, -0.0200, -0.0143],\n",
      "          [-0.0203, -0.0230, -0.0238],\n",
      "          [-0.0081, -0.0320, -0.0038]]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.6.bias | Size: torch.Size([32]) | Values : tensor([ 0.0016, -0.0026], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.9.weight | Size: torch.Size([16, 32, 3, 3]) | Values : tensor([[[[-3.5676e-02,  5.6530e-02,  4.9516e-02],\n",
      "          [-3.3432e-02, -1.4692e-02,  1.7340e-02],\n",
      "          [ 1.1519e-02,  4.0889e-02, -3.6232e-02]],\n",
      "\n",
      "         [[-5.3018e-02,  4.1075e-02,  3.8831e-02],\n",
      "          [ 5.7191e-02, -4.4338e-02, -1.2135e-02],\n",
      "          [ 3.4013e-02,  2.9056e-02,  1.7003e-02]],\n",
      "\n",
      "         [[ 3.6356e-02, -2.6371e-02, -2.4892e-02],\n",
      "          [ 2.3206e-02, -4.5819e-02, -1.2085e-03],\n",
      "          [-5.5448e-02,  2.8784e-02,  1.9976e-02]],\n",
      "\n",
      "         [[ 4.3441e-02, -3.0688e-02,  3.4139e-02],\n",
      "          [-4.3995e-02,  5.4560e-02, -3.2123e-02],\n",
      "          [ 3.4659e-02,  2.8711e-02,  2.1739e-02]],\n",
      "\n",
      "         [[ 4.6548e-02, -4.8194e-02, -4.2961e-02],\n",
      "          [-2.1353e-02,  2.4128e-02,  5.2246e-02],\n",
      "          [-1.0667e-02, -3.3547e-02, -1.9029e-02]],\n",
      "\n",
      "         [[ 3.1801e-02, -5.7173e-02, -2.0695e-02],\n",
      "          [ 3.1803e-03, -3.6883e-02,  7.7856e-03],\n",
      "          [ 3.2082e-02,  4.3698e-02,  2.9844e-02]],\n",
      "\n",
      "         [[-4.4958e-02,  2.5969e-02, -3.4649e-02],\n",
      "          [-3.6431e-02,  3.2329e-03,  3.2103e-02],\n",
      "          [-4.8857e-02, -4.0662e-02, -5.2895e-02]],\n",
      "\n",
      "         [[-5.0739e-02, -1.2753e-02,  1.3441e-02],\n",
      "          [ 2.3791e-04,  2.2178e-03, -4.6866e-02],\n",
      "          [-3.3266e-02,  6.6603e-03, -6.2528e-04]],\n",
      "\n",
      "         [[ 5.5472e-03,  4.8043e-02, -1.1890e-03],\n",
      "          [-3.0907e-02, -5.6941e-02,  2.2478e-02],\n",
      "          [-3.2596e-02,  1.3003e-02, -3.2919e-02]],\n",
      "\n",
      "         [[-5.0722e-02, -4.2145e-02,  2.8674e-05],\n",
      "          [-2.4051e-02,  3.1059e-02,  1.1218e-02],\n",
      "          [ 3.3309e-02, -4.9094e-02, -2.3316e-02]],\n",
      "\n",
      "         [[-3.5666e-02, -4.8017e-02, -2.1936e-02],\n",
      "          [ 2.7217e-02,  1.9753e-02,  1.8063e-02],\n",
      "          [-1.7137e-02, -5.4694e-03,  2.3624e-02]],\n",
      "\n",
      "         [[-5.5469e-02,  6.3458e-03, -1.2497e-02],\n",
      "          [ 1.7595e-03, -4.3687e-02, -3.6948e-02],\n",
      "          [-2.0466e-02, -1.5056e-02, -3.8879e-02]],\n",
      "\n",
      "         [[ 4.3879e-02, -5.5856e-02, -2.3796e-02],\n",
      "          [ 2.8153e-02,  1.2067e-02,  1.8081e-02],\n",
      "          [ 3.1876e-02,  2.3308e-02,  1.0797e-02]],\n",
      "\n",
      "         [[-7.1130e-03,  3.3521e-02, -3.6690e-02],\n",
      "          [-3.4244e-02,  3.2671e-02, -5.1535e-02],\n",
      "          [-2.5516e-02, -1.9744e-02,  5.0912e-03]],\n",
      "\n",
      "         [[-3.9203e-02,  2.5627e-02,  5.0839e-02],\n",
      "          [ 3.3478e-02, -2.7821e-02,  4.0861e-02],\n",
      "          [-8.4038e-03, -5.3365e-02,  8.0047e-03]],\n",
      "\n",
      "         [[ 3.0085e-02,  2.1238e-02,  1.0712e-03],\n",
      "          [-4.2231e-02,  4.0814e-02,  3.4807e-02],\n",
      "          [ 3.8660e-02, -2.1521e-02, -3.2028e-02]],\n",
      "\n",
      "         [[ 5.8065e-02, -1.6697e-02, -5.2031e-02],\n",
      "          [ 1.3558e-03, -1.2747e-03, -4.1114e-02],\n",
      "          [-1.9163e-02,  2.9585e-02,  4.3650e-02]],\n",
      "\n",
      "         [[-3.6930e-02,  7.8818e-03,  5.7074e-03],\n",
      "          [-7.0631e-03,  9.5769e-03, -2.4117e-02],\n",
      "          [-3.4307e-02, -1.2823e-02, -4.8045e-02]],\n",
      "\n",
      "         [[-1.2113e-02, -4.4393e-02,  3.8524e-02],\n",
      "          [ 1.2179e-02, -1.0131e-02, -6.0761e-03],\n",
      "          [-2.5824e-02,  4.3319e-02,  7.1864e-04]],\n",
      "\n",
      "         [[-4.5213e-03, -4.5845e-03, -3.0199e-02],\n",
      "          [ 3.6596e-03, -2.4008e-02,  4.7784e-02],\n",
      "          [ 5.4965e-02, -4.8486e-02, -5.3400e-02]],\n",
      "\n",
      "         [[-2.6798e-02,  2.2863e-02, -3.9816e-02],\n",
      "          [-2.0373e-02, -1.9208e-02,  2.3921e-02],\n",
      "          [ 4.5761e-02,  4.7707e-02,  4.2638e-02]],\n",
      "\n",
      "         [[-3.7833e-02,  2.1101e-02,  1.9703e-02],\n",
      "          [-4.3501e-02, -5.5969e-02,  8.9494e-03],\n",
      "          [ 3.4105e-02, -5.8021e-02, -6.5981e-03]],\n",
      "\n",
      "         [[ 4.4035e-02,  2.1364e-02,  4.8746e-02],\n",
      "          [ 5.2059e-02, -2.2877e-02,  2.5810e-02],\n",
      "          [-3.3130e-02, -2.6905e-02,  5.8745e-03]],\n",
      "\n",
      "         [[-2.8902e-02,  4.2487e-03,  5.6764e-02],\n",
      "          [ 4.6910e-02,  4.8068e-02, -4.9210e-02],\n",
      "          [-3.6884e-02, -4.6480e-02, -4.4562e-02]],\n",
      "\n",
      "         [[-2.1628e-02, -2.6333e-02,  2.5994e-02],\n",
      "          [ 1.0163e-02,  2.5186e-02, -2.9305e-02],\n",
      "          [ 4.6072e-02, -5.3479e-02,  3.5184e-02]],\n",
      "\n",
      "         [[ 3.6210e-02, -2.2114e-02,  8.5583e-03],\n",
      "          [-9.2006e-03,  4.3769e-02, -1.3942e-02],\n",
      "          [-5.2334e-03,  4.1258e-02, -3.7516e-02]],\n",
      "\n",
      "         [[-5.0518e-02, -4.1818e-02, -5.6386e-02],\n",
      "          [-1.6053e-02, -3.3616e-02,  3.6417e-02],\n",
      "          [ 6.3217e-03,  1.6229e-02,  5.6825e-02]],\n",
      "\n",
      "         [[-3.6058e-02, -4.7564e-02, -4.7313e-02],\n",
      "          [ 2.6758e-02,  3.7881e-02,  5.6078e-02],\n",
      "          [-4.5961e-03, -2.6412e-02, -3.8711e-02]],\n",
      "\n",
      "         [[ 7.6362e-03,  3.1128e-02,  3.2887e-02],\n",
      "          [ 5.9996e-05,  8.0784e-03, -2.2884e-02],\n",
      "          [ 4.1409e-02, -3.2734e-02, -2.7012e-02]],\n",
      "\n",
      "         [[ 5.8671e-02,  1.2264e-02,  4.8706e-02],\n",
      "          [-5.2699e-02, -4.6739e-02, -3.3799e-02],\n",
      "          [-2.9632e-02, -4.9095e-02,  4.9242e-02]],\n",
      "\n",
      "         [[ 9.4123e-03,  4.7858e-02, -1.6693e-02],\n",
      "          [ 1.9606e-02, -4.6333e-02,  4.9258e-02],\n",
      "          [ 3.7524e-03, -4.4027e-02, -2.6042e-02]],\n",
      "\n",
      "         [[-1.9990e-02, -5.1721e-02, -3.5252e-02],\n",
      "          [ 2.7793e-02, -6.3333e-03,  2.9753e-02],\n",
      "          [-2.3783e-02,  5.0094e-03,  1.6994e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3979e-03, -4.9160e-02, -8.9194e-03],\n",
      "          [ 2.6866e-02, -6.9403e-03, -4.6129e-02],\n",
      "          [ 4.3605e-02,  1.5745e-02,  3.4566e-03]],\n",
      "\n",
      "         [[ 3.9246e-02,  4.6697e-02,  1.2155e-02],\n",
      "          [-4.7784e-02,  3.2138e-02, -3.0094e-02],\n",
      "          [ 4.3253e-02,  3.5002e-02,  1.4546e-02]],\n",
      "\n",
      "         [[-1.1364e-02,  9.6006e-03, -2.5576e-03],\n",
      "          [ 3.4527e-02,  1.7891e-02,  1.1345e-02],\n",
      "          [-1.9292e-02, -2.8376e-02, -1.7641e-02]],\n",
      "\n",
      "         [[ 3.3769e-02,  1.9544e-02, -1.5220e-02],\n",
      "          [-3.0113e-02, -5.1762e-02,  4.3410e-02],\n",
      "          [-3.4793e-02, -5.6692e-03, -4.6535e-03]],\n",
      "\n",
      "         [[ 4.8447e-02, -4.8027e-02,  2.3015e-02],\n",
      "          [ 5.5234e-02,  4.9321e-02, -5.1330e-02],\n",
      "          [-4.7758e-03,  3.4964e-03,  5.5348e-02]],\n",
      "\n",
      "         [[ 3.1547e-02,  7.1815e-03,  1.5619e-03],\n",
      "          [-1.4017e-02,  1.0056e-02,  9.3569e-03],\n",
      "          [-5.8108e-03,  1.4046e-03,  5.4508e-02]],\n",
      "\n",
      "         [[ 2.3607e-02,  4.4922e-02, -5.5053e-02],\n",
      "          [ 4.0452e-02,  2.0869e-03,  5.0871e-02],\n",
      "          [ 4.4838e-03, -5.2362e-02,  7.7215e-03]],\n",
      "\n",
      "         [[ 2.4828e-02, -3.5422e-02, -1.1396e-02],\n",
      "          [ 4.5388e-02, -9.7110e-03,  6.9246e-03],\n",
      "          [ 1.8208e-02,  5.5493e-02,  5.4220e-02]],\n",
      "\n",
      "         [[ 5.5972e-02,  2.5491e-02,  1.2500e-02],\n",
      "          [-1.7378e-02,  2.5710e-02, -4.0477e-02],\n",
      "          [-2.6109e-02,  2.8660e-02, -7.2060e-03]],\n",
      "\n",
      "         [[-4.8545e-02, -4.0134e-02,  3.8038e-02],\n",
      "          [-5.9640e-03,  5.3214e-02, -4.7570e-02],\n",
      "          [-2.0541e-02, -5.1580e-02,  2.6241e-02]],\n",
      "\n",
      "         [[-4.3675e-02, -1.3240e-02,  2.9165e-02],\n",
      "          [ 5.3542e-03,  1.5028e-02,  9.5437e-04],\n",
      "          [-9.8209e-05,  4.5639e-02, -5.5619e-02]],\n",
      "\n",
      "         [[-5.4184e-02, -5.1599e-02, -4.3430e-02],\n",
      "          [ 6.0269e-03, -2.8606e-02, -4.6402e-02],\n",
      "          [-3.5027e-02, -2.3628e-02, -5.5166e-03]],\n",
      "\n",
      "         [[ 2.4174e-02,  1.2786e-02,  5.6962e-03],\n",
      "          [ 4.9241e-02,  1.2853e-02,  5.5218e-02],\n",
      "          [-5.1590e-02,  3.0628e-02, -6.9590e-03]],\n",
      "\n",
      "         [[ 2.9675e-03, -1.7481e-02,  2.0095e-02],\n",
      "          [-5.5292e-02,  3.6633e-02,  4.8668e-02],\n",
      "          [ 1.1708e-02, -5.2316e-02,  4.3868e-02]],\n",
      "\n",
      "         [[ 2.6868e-02,  4.6024e-02, -3.6299e-02],\n",
      "          [-3.0909e-02,  5.2879e-02, -7.2285e-03],\n",
      "          [ 5.3612e-02, -2.6216e-02, -5.6558e-03]],\n",
      "\n",
      "         [[-2.5686e-02, -5.3978e-02,  3.2054e-02],\n",
      "          [ 5.5716e-02, -3.6547e-02,  1.9886e-02],\n",
      "          [ 5.0142e-02, -4.1207e-02,  5.2158e-02]],\n",
      "\n",
      "         [[ 4.7639e-03, -4.8502e-02,  4.9714e-02],\n",
      "          [ 2.0729e-02,  2.7174e-02, -4.6048e-02],\n",
      "          [-5.6227e-02, -1.6698e-02, -2.6481e-02]],\n",
      "\n",
      "         [[ 3.6936e-02, -9.7891e-03, -1.1125e-02],\n",
      "          [ 1.5612e-02,  8.1004e-03,  8.4735e-03],\n",
      "          [-3.3814e-02, -2.5501e-02, -3.0479e-03]],\n",
      "\n",
      "         [[-1.3920e-02, -5.9368e-03, -5.7230e-02],\n",
      "          [ 3.3342e-02,  3.9514e-02, -4.6427e-02],\n",
      "          [ 4.4055e-02, -4.5434e-02, -4.0498e-02]],\n",
      "\n",
      "         [[ 2.4947e-02, -5.4216e-02,  1.3898e-02],\n",
      "          [-6.1625e-03, -1.5365e-02, -4.2804e-02],\n",
      "          [ 4.4756e-02,  9.9331e-04,  2.6079e-02]],\n",
      "\n",
      "         [[-1.0511e-02,  6.8306e-03, -5.3987e-03],\n",
      "          [ 3.0793e-02,  1.1126e-02, -5.6816e-02],\n",
      "          [-4.2681e-03, -3.2737e-02, -4.2565e-02]],\n",
      "\n",
      "         [[ 5.1780e-03, -1.4066e-02,  3.6991e-02],\n",
      "          [-1.6315e-02,  3.4760e-02,  4.4251e-02],\n",
      "          [ 2.0248e-02, -1.6675e-03,  7.6211e-03]],\n",
      "\n",
      "         [[ 3.0072e-02, -3.5396e-02,  2.9691e-02],\n",
      "          [ 1.3870e-02,  8.0188e-03,  9.2696e-03],\n",
      "          [-5.6504e-02,  2.7322e-02,  3.5605e-02]],\n",
      "\n",
      "         [[ 2.3763e-02, -2.5526e-02,  3.3544e-02],\n",
      "          [-2.9648e-02, -2.6035e-02, -4.3209e-02],\n",
      "          [ 7.7390e-03,  5.2827e-02,  4.6629e-02]],\n",
      "\n",
      "         [[-2.2064e-02,  2.5767e-02,  3.1217e-02],\n",
      "          [ 2.3484e-02,  5.7106e-02, -4.3399e-02],\n",
      "          [ 3.6891e-02, -5.2955e-02, -3.7634e-02]],\n",
      "\n",
      "         [[-2.3329e-02,  1.3668e-03,  5.5563e-02],\n",
      "          [ 1.6516e-04, -2.4773e-02,  4.8129e-02],\n",
      "          [ 1.7118e-02,  1.8660e-02, -4.4807e-03]],\n",
      "\n",
      "         [[-2.3821e-02,  2.2929e-02, -3.4905e-02],\n",
      "          [ 1.7678e-02, -4.5893e-02,  3.1085e-02],\n",
      "          [ 4.1428e-02, -2.7957e-02, -1.5790e-02]],\n",
      "\n",
      "         [[ 5.4416e-02, -2.1075e-02, -4.0346e-02],\n",
      "          [-1.8918e-02,  1.0137e-02, -1.7809e-02],\n",
      "          [ 5.0605e-02,  5.8022e-02, -1.5489e-03]],\n",
      "\n",
      "         [[-5.3492e-03,  3.9384e-02, -1.1037e-02],\n",
      "          [-5.7019e-02,  5.2214e-02,  6.6596e-03],\n",
      "          [ 2.8241e-02,  4.5918e-02, -8.0062e-03]],\n",
      "\n",
      "         [[-3.5516e-02,  3.9996e-02,  1.8421e-02],\n",
      "          [-5.7342e-02,  3.8319e-02,  1.3981e-02],\n",
      "          [ 9.0400e-03,  5.7172e-02,  1.0425e-02]],\n",
      "\n",
      "         [[ 1.0622e-02,  2.5965e-02,  2.5011e-03],\n",
      "          [-3.0572e-02,  2.0788e-02,  3.0128e-02],\n",
      "          [-3.8685e-02, -1.1409e-02, -5.4067e-02]],\n",
      "\n",
      "         [[ 5.0515e-02, -2.0427e-02,  1.5148e-02],\n",
      "          [ 2.2188e-02,  4.1302e-02, -2.4957e-02],\n",
      "          [ 2.4182e-02,  3.5859e-02,  2.5212e-02]]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv_layers.9.bias | Size: torch.Size([16]) | Values : tensor([-0.0547,  0.0382], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc_layers.1.weight | Size: torch.Size([512, 7744]) | Values : tensor([[-0.0015, -0.0058,  0.0021,  ..., -0.0076, -0.0103, -0.0091],\n",
      "        [ 0.0017, -0.0064, -0.0009,  ..., -0.0048, -0.0048,  0.0003]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc_layers.1.bias | Size: torch.Size([512]) | Values : tensor([0.0077, 0.0030], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc_layers.3.weight | Size: torch.Size([1, 512]) | Values : tensor([[-4.1660e-02, -1.2220e-03, -4.1898e-02,  4.2033e-02, -4.0719e-03,\n",
      "         -2.5872e-02, -9.0940e-04,  1.6577e-02, -1.9061e-02, -2.3064e-02,\n",
      "          2.7139e-02,  1.4422e-02,  3.2159e-02, -3.6904e-02,  2.6485e-02,\n",
      "         -6.2910e-03, -5.5642e-03, -3.7793e-02,  3.5404e-02,  2.7192e-02,\n",
      "          3.8606e-02, -1.7812e-02, -4.2400e-02,  8.1768e-03,  2.9130e-03,\n",
      "          4.4112e-02,  3.9858e-02, -2.6957e-02,  3.5864e-02,  2.2995e-02,\n",
      "         -6.2872e-03,  5.5201e-03, -2.6304e-02,  1.5876e-02, -9.1531e-03,\n",
      "         -4.0990e-02,  1.9679e-02, -3.2702e-02, -3.2581e-03,  1.6190e-02,\n",
      "         -1.6724e-02,  1.3946e-02,  3.1390e-03, -2.2635e-02,  7.9882e-03,\n",
      "          4.2961e-04, -3.7446e-02, -7.4531e-03,  3.2328e-02, -2.0106e-02,\n",
      "         -2.3492e-02,  2.5872e-02,  2.1756e-02,  4.0987e-02, -1.5278e-02,\n",
      "          2.9805e-02,  4.2364e-02, -1.3749e-02, -3.6142e-02,  1.2240e-02,\n",
      "         -1.0884e-02, -2.7819e-02,  3.8831e-02, -1.3358e-02,  4.1036e-02,\n",
      "         -3.9098e-02,  1.1731e-02, -2.8250e-02,  8.2228e-03, -4.0773e-02,\n",
      "         -3.3402e-02,  1.1526e-02, -4.1660e-02,  3.4592e-02, -4.1762e-02,\n",
      "         -1.7200e-02,  1.0671e-02,  6.0171e-03, -4.3893e-03, -2.2564e-02,\n",
      "          3.8934e-02, -5.8882e-03, -3.9263e-02,  7.9557e-05,  3.1023e-03,\n",
      "          4.0067e-02,  2.3822e-02,  3.4047e-02, -1.6499e-02, -5.8940e-03,\n",
      "         -3.5736e-02, -3.3979e-02, -1.7147e-02, -1.1879e-02,  2.6674e-02,\n",
      "          2.1791e-03, -2.6712e-02, -2.7366e-02,  1.4356e-02, -1.1582e-02,\n",
      "         -5.8112e-03, -3.7226e-02, -1.2853e-02, -4.3701e-02, -2.9430e-02,\n",
      "         -1.1312e-02,  1.7963e-02,  2.1738e-02,  3.6112e-03, -3.3290e-02,\n",
      "         -1.6911e-02, -2.6361e-02, -1.7589e-02, -1.8183e-02,  4.1952e-02,\n",
      "         -2.0816e-02, -3.9978e-02, -9.7760e-03, -3.5090e-02, -7.0228e-04,\n",
      "          3.2059e-02, -1.7208e-02, -1.7705e-02,  2.1427e-02,  2.2952e-02,\n",
      "          3.8876e-03, -5.6354e-04,  4.3853e-03, -2.1095e-02,  1.5126e-02,\n",
      "         -3.6530e-02,  2.3254e-02,  1.8869e-02,  2.3592e-02,  1.2816e-02,\n",
      "          2.0805e-02,  2.1802e-02,  2.7007e-02, -4.2611e-02, -4.3502e-02,\n",
      "          2.2652e-02, -1.2426e-02, -1.2731e-02,  1.0424e-02,  1.9033e-03,\n",
      "         -2.2205e-02, -2.1533e-02, -1.5440e-02,  2.3086e-02, -3.5547e-02,\n",
      "         -2.1217e-02,  1.3597e-02, -8.3680e-03, -3.4642e-02,  3.6538e-02,\n",
      "         -3.3502e-02, -4.1686e-02, -3.4607e-02, -2.3320e-02,  2.0642e-02,\n",
      "         -1.5832e-02, -1.8610e-02, -3.2013e-02,  3.5597e-02, -2.4044e-02,\n",
      "         -3.3531e-02, -4.0133e-02, -3.6299e-02, -3.3020e-02,  2.6311e-02,\n",
      "         -3.3531e-02,  4.3625e-02,  4.3016e-02, -1.3359e-02,  1.9801e-02,\n",
      "          3.4435e-02, -2.2287e-02,  3.7385e-02,  1.6979e-02,  2.2179e-02,\n",
      "         -4.2404e-02,  2.1662e-02, -2.5100e-02,  1.7905e-02, -4.3502e-02,\n",
      "         -7.2264e-03,  2.2908e-02,  2.6510e-02,  4.2192e-02,  4.2507e-02,\n",
      "         -3.4551e-02, -3.2694e-02, -1.9185e-02,  8.6675e-03, -1.9532e-02,\n",
      "          2.9924e-02,  1.1089e-02, -1.4889e-03,  2.6408e-02, -2.3181e-02,\n",
      "         -4.0583e-02, -2.3721e-02,  2.3602e-02, -4.1178e-02,  8.3737e-03,\n",
      "         -4.7520e-03,  3.7553e-02, -1.6689e-03,  2.3554e-02,  2.6472e-02,\n",
      "         -1.6559e-02,  1.3805e-02, -1.0172e-02,  4.4093e-02, -1.2862e-03,\n",
      "         -2.4147e-02, -1.4447e-02, -2.8971e-02, -2.5638e-02,  1.6932e-02,\n",
      "         -1.2299e-02,  2.4742e-02, -2.6255e-02,  4.3063e-02, -2.4163e-02,\n",
      "          2.7573e-02, -3.4352e-03, -3.3747e-02,  3.9504e-02, -7.9881e-03,\n",
      "          2.1982e-02,  4.1352e-02,  2.3722e-02,  3.8029e-03, -1.1198e-02,\n",
      "         -3.4788e-02, -2.7537e-02, -1.6907e-02,  2.6886e-02, -2.3578e-02,\n",
      "         -1.3106e-02,  1.6913e-02,  1.0059e-02,  3.8906e-02,  2.9938e-02,\n",
      "         -1.8452e-02,  3.4080e-02,  2.2335e-02, -2.0519e-02,  2.7126e-02,\n",
      "          4.8438e-03, -3.2751e-03, -1.3153e-02,  2.0789e-02,  1.0657e-02,\n",
      "         -1.1465e-02,  3.3268e-03,  1.5521e-02,  4.7911e-03,  1.5682e-02,\n",
      "          1.8534e-02, -2.6215e-02,  2.4896e-02, -1.0418e-02,  1.2553e-02,\n",
      "          1.0288e-02, -2.1069e-02, -3.2240e-02, -1.5368e-02, -2.8745e-02,\n",
      "          3.9332e-02, -3.6357e-02, -1.6817e-03,  4.0281e-02,  2.1831e-02,\n",
      "          4.8122e-03,  3.0159e-02, -3.9167e-04, -6.7231e-03, -1.5749e-02,\n",
      "          1.1179e-02, -3.5104e-02,  3.8732e-02,  3.5526e-02,  3.5545e-02,\n",
      "         -2.1287e-02,  3.7054e-02,  2.9242e-02, -2.2202e-02,  4.3669e-02,\n",
      "         -2.0024e-03,  3.1024e-02, -2.8028e-02, -4.2697e-02,  1.1259e-02,\n",
      "         -3.0454e-02, -3.7514e-02, -1.2208e-02,  4.1450e-02, -1.4278e-02,\n",
      "         -1.8598e-02, -2.7540e-02,  6.3589e-03,  2.7769e-03,  2.5081e-02,\n",
      "          2.4589e-03,  3.6402e-02, -4.2740e-02,  2.0264e-02,  1.0504e-02,\n",
      "         -3.3016e-02, -2.1711e-02,  1.0186e-02,  1.9134e-02, -2.7892e-03,\n",
      "         -4.8464e-03,  3.4007e-02, -4.9922e-03, -4.1464e-03,  2.2432e-02,\n",
      "         -3.1663e-02, -3.3108e-02, -1.9329e-02,  4.6299e-03, -4.2591e-02,\n",
      "         -9.0068e-03, -3.6674e-04,  1.4673e-02,  2.6191e-02,  1.3041e-02,\n",
      "          1.2989e-02, -1.2869e-02,  1.2408e-02,  1.2842e-02,  1.4112e-03,\n",
      "          2.6207e-02, -1.2419e-02,  1.4522e-02,  3.4941e-02,  3.3556e-02,\n",
      "         -4.1819e-02,  2.9985e-02, -1.6957e-02, -4.1190e-02,  1.9838e-02,\n",
      "          1.5995e-02,  4.1955e-02,  1.5725e-02, -3.2424e-02, -1.4448e-02,\n",
      "          2.0519e-02, -4.3316e-02, -9.3400e-03, -2.0781e-02, -1.3509e-02,\n",
      "          2.1382e-02, -2.1531e-02, -2.3658e-03, -2.2386e-02, -3.2310e-04,\n",
      "          2.4859e-02,  2.2524e-02, -1.8723e-02,  1.8074e-02,  5.5678e-03,\n",
      "          1.6927e-05, -1.4052e-02,  1.2604e-02, -3.1958e-02, -2.7138e-03,\n",
      "          4.1101e-02, -9.9610e-03, -2.8031e-03, -3.4553e-02,  9.9020e-03,\n",
      "          2.0723e-03, -8.3921e-03,  2.4612e-02, -8.7669e-04, -3.4752e-02,\n",
      "          1.0178e-02,  1.0834e-02, -1.1285e-02, -9.6087e-03, -1.1757e-02,\n",
      "          2.7229e-02,  1.5544e-02, -7.1764e-03, -3.2033e-02, -2.2826e-02,\n",
      "         -9.6880e-03,  3.7579e-02,  2.0723e-02,  3.6589e-02,  2.2178e-02,\n",
      "          3.0558e-02, -8.5902e-03, -4.1164e-02, -2.2604e-02, -2.0534e-04,\n",
      "          3.6710e-02, -3.1868e-02,  1.9620e-02,  3.4681e-02, -1.6786e-02,\n",
      "         -3.1335e-02,  1.5592e-02, -2.5429e-02, -3.9700e-02, -3.6453e-03,\n",
      "          1.5870e-02,  4.1133e-02, -8.1549e-03, -3.9141e-02, -2.9788e-02,\n",
      "         -3.5355e-03,  2.1161e-02, -2.6893e-02,  4.9352e-04,  3.6505e-02,\n",
      "         -3.8367e-02,  1.3058e-02, -3.5579e-02,  2.2577e-02,  1.5980e-02,\n",
      "         -3.2664e-02, -4.2421e-02, -3.1754e-02,  4.1001e-02,  3.2748e-02,\n",
      "          1.9554e-02, -1.8528e-02,  1.9909e-02, -1.5544e-02,  3.1589e-02,\n",
      "          4.0498e-02, -6.1766e-03, -1.0862e-02,  3.6123e-02, -3.2122e-02,\n",
      "          5.3286e-03, -4.4045e-02, -3.9540e-02,  4.2721e-02,  2.7030e-02,\n",
      "         -1.8180e-02,  3.8548e-03, -2.7430e-02, -3.7300e-02, -2.4119e-02,\n",
      "          2.8371e-03,  1.2424e-03,  2.2231e-02, -1.6632e-02, -2.8917e-02,\n",
      "         -2.2583e-02, -2.9531e-02, -3.7117e-03, -4.2833e-02,  3.6939e-02,\n",
      "         -4.8165e-03,  3.8891e-02,  2.2387e-03,  3.0497e-02,  3.8033e-02,\n",
      "          1.3925e-02,  2.1779e-02,  3.6348e-02, -1.1973e-02,  3.7050e-02,\n",
      "         -4.1193e-02,  1.0996e-02, -3.3453e-02,  1.3518e-02, -2.7554e-02,\n",
      "          2.5439e-02, -1.3738e-02, -1.8033e-02, -4.3281e-02,  2.4921e-02,\n",
      "         -5.6709e-03, -3.0308e-03,  4.3282e-02,  3.7992e-02,  4.0490e-02,\n",
      "         -3.5252e-02, -1.7914e-02,  3.6416e-02,  3.2569e-02, -2.8340e-02,\n",
      "          3.3907e-02, -1.5231e-02, -1.9801e-02, -4.1438e-02, -3.6174e-02,\n",
      "         -3.2062e-02,  1.6020e-02, -8.7932e-03, -1.6394e-02,  4.3734e-02,\n",
      "          1.9891e-02, -3.0195e-02,  3.4193e-02,  1.6746e-02,  2.1024e-02,\n",
      "         -2.4120e-02, -2.7563e-02, -2.6484e-02,  2.6278e-02, -4.1852e-02,\n",
      "          2.9624e-02, -4.3390e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc_layers.3.bias | Size: torch.Size([1]) | Values : tensor([-0.0418], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318dbe9a-3d6a-485e-a066-0325d1d38694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(data, model, loss_fn, class_to_idx):\n",
    "    size = len(data.dataset)\n",
    "    num_batches = len(data)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data:\n",
    "            batch_labels_numeric = [class_to_idx[label] for label in y]\n",
    "            y = torch.tensor(batch_labels_numeric, dtype=torch.float32)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            pred = pred.squeeze(1)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.round(pred) == y).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100 * correct\n",
    "    print(f\"Test Error: Accuracy: {accuracy:.2f}% | Avg loss: {test_loss:.8f}\\n\")\n",
    "\n",
    "# Exemplo de uso\n",
    "class_to_idx = {\"psoriasis\": 1, \"melanome\": 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "493b2e12-ba97-4cb9-b3ca-4bb02c51bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Loss: 0.6830786  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.68482550\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Loss: 0.6897627  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.68342733\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Loss: 0.6834214  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.68290740\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Loss: 0.6836227  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.68169956\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Loss: 0.6844045  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.68047551\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Loss: 0.6835147  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.67810513\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Loss: 0.6758238  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.67933142\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Loss: 0.6743531  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.67417135\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Loss: 0.6728649  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.67129369\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Loss: 0.6740884  [    0/  637]\n",
      "Test Error: Accuracy: 70.80% | Avg loss: 0.67605038\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Definir as funções de perda e otimizadores\n",
    "##input (Tensor) – Tensor of arbitrary shape as probabilities.\n",
    "##target (Tensor) – Tensor of the same shape as input with values between 0 and 1.\n",
    "# testar esse learning rate lr=0.01\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer, class_to_idx)\n",
    "    \n",
    "    test(test_loader, model, loss_fn, class_to_idx)\n",
    "print(\"Done!\")\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec164ee-6467-4d18-8cfc-aa25fef81654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad68af-3242-4c44-b516-edde8a45d442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
